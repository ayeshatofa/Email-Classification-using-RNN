# ðŸ“§ Email Classification Using RNN & LSTM
### Neural Networks & Fuzzy Logic (NNFL) Project
This project implements an end-to-end email classification system using Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) networks. The system classifies emails as ham (legitimate) or spam using deep learning.

The project includes:
- Dataset loading & cleaning
- Exploratory Data Analysis (EDA)
- Text preprocessing
- RNN and LSTM model training
- Evaluation (accuracy, confusion matrix, precision, recall, F1)
- Custom email prediction pipeline
## ðŸš€ Features
- Raw email text preprocessing (tokenization, stemming, stopword removal, n-grams)
- Train/validation/test split with stratification
- Deep learning-based text classification
- RNN baseline model
- LSTM enhanced model
- Model checkpointing + early stopping
- Confusion matrix & metrics visualization
- Custom email prediction function
- Ready for deployment/inference
## ðŸ§  Project Architecture
```
Email_Classification_NNFL/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Emailscam.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ email_classification.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_rnn.weights.h5
â”‚   â””â”€â”€ best_lstm.weights.h5
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â””â”€â”€ classification_report.txt
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
## ðŸ“Š Dataset
- Source: Mendeley Data
- Classes:
  - ham: legitimate messages
  - spam: unsolicited / fraudulent messages
    
Load dataset:
```
df = pd.read_csv(
    "https://raw.githubusercontent.com/ayeshatofa/Email-Classification-using-RNN/main/Emailscam.csv",
    encoding="latin1"
)
```
## ðŸ” Exploratory Data Analysis (EDA)
The notebook includes visualizations for:
- Class distribution
- Word count analysis
- Punctuation frequency
- Stopword count
- URL frequency
- Frequent spam vs ham words

## ðŸ›  Text Preprocessing
Preprocessing steps include:
- Lowercasing
- Emoji removal
- Punctuation removal
- Stopword removal
- Stemming (PorterStemmer)
- Bigram generation
- Tokenization
- Sequence padding

```
processed_sentence = preprocessing(text)
processed_sentence = stopwordRemoval(processed_sentence)
processed_sentence = stem_text(processed_sentence)
processed_sentence = ' '.join(generate_ngrams(processed_sentence, n=2))
```

## ðŸ¤– Model Development
### SimpleRNN Model
- Embedding layer
- SimpleRNN(64)
- Dense layers with dropout
### LSTM Model
- Embedding layer
- LSTM(64) with dropout
- Dense classifier
### Training Setup
- Loss: binary_crossentropy
- Optimizer: adam
- Batch size: 32
- Epochs: 20
- EarlyStopping
- ModelCheckpoint

## ðŸ“ˆ Evaluation
### RNN Performance

| Metric               | Score   |
|----------------------|---------|
| **Accuracy**         | 0.9731  |
| **Loss**             | 0.0949  |
| **Precision (weighted)** | 0.7492  |
| **Recall (weighted)**    | 0.8656  |
| **F1 Score**             | 0.8032  |

### LSTM Performance
| Metric               | Score   |
|----------------------|---------|
| **Accuracy**         | 0.9821  |
| **Loss**             | 0.0705  |
| **Precision (weighted)** | 0.7492  |
| **Recall (weighted)**    | 0.8656  |
| **F1 Score**             | 0.8032  |
### Confusion Matrix (Both Models)
[[483   0]
 [ 75   0]]

**âš  Note**: Both models predicted all instances as ham due to dataset imbalance and heavy preprocessing, causing 0% recall on spam.

## ðŸ§ª Custom Email Prediction
```
pred = model.predict(padded_seq)
pred_class = label_encoder.classes_[int(pred[0][0] > 0.5)]
print("Predicted Label:", pred_class)
```

## âš  Limitations
- Dataset imbalance â†’ poor spam detection
- Heavy preprocessing removed useful patterns
- No class weighting used
- Simple RNN/LSTM architecture; lacks attention/transformers

## ðŸ”® Future Improvements
- Use class weights (e.g., class_weight='balanced')
- Apply SMOTE or oversampling for spam
- Include metadata features (sender, domain)
- Switch to BERT, DistilBERT, or Transformer models
- Refine preprocessing (keep URLs, moderate stopword removal)

## â–¶ How to Run
1.	Clone the repo:
```
git clone https://github.com/ayeshatofa/Email-Classification-using-RNN.git
cd Email-Classification-using-RNN
```
2.	Install dependencies:
```
pip install -r requirements.txt
```
3.	Open the notebook:
```
code CODE_2257_1002_1026.ipynb
```
4.	Run all cells to train models / test predictions.
